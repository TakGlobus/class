{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functinos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_list(nx=64,ny=64,height=2,width=1,stride=1):\n",
    "    f12_list = []\n",
    "    f21_list = []\n",
    "    for j in range(0,ny,stride):\n",
    "        for i in range(0,nx, stride):\n",
    "            ### 1 by 2 (x by y)\n",
    "            if i+stride+width <= nx-1 and j+height <= ny-1:\n",
    "                #shaded\n",
    "                xs, ys  = i,j # upper left\n",
    "                _xs,_ys = i+width, j+height# bottom right\n",
    "                # unshaded\n",
    "                xu, yu  = i+stride,j # upper left\n",
    "                _xu,_yu = i+stride+width, j+height# bottom right\n",
    "                # shaded + unshaded\n",
    "                f12_list += [[[xs, ys],[_xs, _ys],[xu, yu],[_xu, _yu]]]\n",
    "            ### 2 by 1 (x by y)\n",
    "            if i+stride+width <= nx-1 and j+stride+width <= ny-1:\n",
    "                #shaded\n",
    "                xs, ys  = i,j # upper left\n",
    "                _xs,_ys = i+height, j+width# bottom right\n",
    "                # unshaded\n",
    "                xu, yu  = i,j+stride # upper left\n",
    "                _xu,_yu = i+height, j+stride+width# bottom right\n",
    "                # shaded + unshaded\n",
    "                f21_list += [[[xs, ys],[_xs, _ys],[xu, yu],[_xu, _yu]]]\n",
    "    return f12_list+f21_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_feature(int_img_rep, feat_lst, feat_idx):\n",
    "    \"\"\" int_img_rep: the N x 64 x 64 numpy matrix of the integral image representation\n",
    "        feat_lst: list of features\n",
    "        feat_idx: integer, index of a feature (in feat_lst)\n",
    "        Returns: an N x 1 numpy matrix of the feature evaluations for each image\n",
    "    \"\"\"\n",
    "    n, nx, ny = int_img_rep.shape\n",
    "    feat_eval = []\n",
    "\n",
    "    def _compute_intensity(int_img, ul, rb):\n",
    "        \"\"\"\n",
    "        compute intensity\n",
    "        x: upper left [ix, jx]\n",
    "        y: bottom right [iy, jy]\n",
    "        \n",
    "        *(ix,iy)---*\n",
    "        |          |\n",
    "        |          |\n",
    "        *----------*(jx,jy)\n",
    "        \"\"\"\n",
    "        ix, iy = ul # upper left x,y\n",
    "        jx, jy = rb #  bottom right x, y\n",
    "        if ix-1 >= 0 and iy-1 >= 0  :\n",
    "            intensity = int_img[jx,jy] + int_img[ix-1,iy-1] - int_img[ix-1,jy] - int_img[jx,iy-1]\n",
    "        elif ix-1 >=0 and iy-1<0:\n",
    "            intensity = int_img[jx,jy] - int_img[ix-1,jy]\n",
    "        elif ix-1 < 0 and iy-1>=0:\n",
    "            intensity = int_img[jx,jy]  - int_img[jx,iy-1]\n",
    "        elif ix-1 < 0 and iy-1< 0:\n",
    "            intensity = int_img[jx,jy] \n",
    "        return intensity\n",
    "    \n",
    "    for img in int_img_rep:\n",
    "        \"\"\"\n",
    "        x: upper left in shaded\n",
    "        y: bottom right in shaded\n",
    "        z: upper left in unshaded\n",
    "        s: bottom right in unshaded\n",
    "        \"\"\"\n",
    "        x,y,z,s = feat_lst[feat_idx] \n",
    "        shaded   = _compute_intensity(img, x,y) \n",
    "        unshaded = _compute_intensity(img, z,s)\n",
    "        feat_eval +=[shaded - unshaded]\n",
    "    \n",
    "    return np.asarray(feat_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_integral_image(imgs):\n",
    "    \"\"\"\n",
    "    IN: imgs. np.ndarray, shape [#images, 64,64]\n",
    "    \"\"\"\n",
    "    \n",
    "    def _compute_int_img_unit(img):\n",
    "        \"\"\"\n",
    "            compute integral image for one image \n",
    "        \"\"\"\n",
    "        nx, ny = img.shape\n",
    "        int_img = np.ones((nx,ny))\n",
    "        int_img[0,0] = img[0,0]\n",
    "        for i in range(nx):\n",
    "            for j in range(ny):\n",
    "                if j > 0 and i > 0:\n",
    "                    int_img[i,j] = int_img[i-1,j] + sum([ img[i,k] for k in range(j+1)])\n",
    "                elif j==0 and i>0:\n",
    "                    int_img[i,0] = int_img[i-1,0] + img[i,0]\n",
    "                elif i==0 and j>0:\n",
    "                    int_img[0,j] = int_img[0,j-1] + img[0,j]\n",
    "        return int_img\n",
    "    \n",
    "    nimg, nx, ny = imgs.shape\n",
    "    int_img_list = []\n",
    "    for img in imgs:\n",
    "        int_img_list += [_compute_int_img_unit(img).reshape(1,nx,ny)]\n",
    "    int_imgs = np.concatenate(int_img_list, axis=0)\n",
    "    return int_imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt_p_theta(int_img_rep, feat_lst, weights, feat_idx, y_true):\n",
    "    \"\"\"\n",
    "    p = {+1,-1}\n",
    "    theta = threshold\n",
    "    \"\"\"\n",
    "    p, theta = 0,0\n",
    "    #value of feature_idx on example 1-All\n",
    "    _eval_list = [] # f(x_sigma)\n",
    "    _eval_list += [compute_feature(int_img_rep=int_img_rep, feat_lst=feat_lst, feat_idx=feat_idx)]\n",
    "    #permutation\n",
    "    _eval_list.sort() # f(x_sigma1) < f(x_sigma2) ... < f(x_sigmaN)\n",
    "    eval_list = np.squeeze(np.asarray(_eval_list))\n",
    "    #print(eval_list.shape)\n",
    "    \n",
    "    #potential theta\n",
    "    thetas = []\n",
    "    for i in range(int_img_rep.shape[0]):\n",
    "        theta_left = eval_list[i]\n",
    "        if i+1 <= len(eval_list)-1:\n",
    "            theta_right = eval_list[i+1]\n",
    "        else:\n",
    "            theta_right = theta_left\n",
    "    \n",
    "        # decide theta\n",
    "        \"\"\"\n",
    "         f(x_sigma_j) <= theta <= f(x_sigma_j+1) j:= feat_idx\n",
    "        \"\"\"\n",
    "        theta = theta_left + (theta_right-theta_left)/2\n",
    "        thetas += [theta]\n",
    "    \n",
    "    #decide p\n",
    "    ps = []\n",
    "    plus_vec  = np.zeros(len(y_true))## length is y_true\n",
    "    minus_vec = np.zeros(len(y_true))\n",
    "    plus_vec[np.where(y_true == 1)] = 1 # binary vector\n",
    "    minus_vec[np.where(y_true == -1)] = 1\n",
    "    \n",
    "    prod_plus = weights*plus_vec\n",
    "    prod_minus = weights*minus_vec\n",
    "    \n",
    "    t_plus = np.sum(prod_plus)\n",
    "    t_minus = np.sum(prod_minus)\n",
    "    for i in range(int_img_rep.shape[0]):\n",
    "        s_plus = np.sum(prod_plus[:i])\n",
    "        s_minus = np.sum(prod_minus[:i])\n",
    "        # Comment out lines are bug\n",
    "        #epsilon = min((s_plus+(t_minus-s_minus)), (s_minus+(t_plus-s_plus)))\n",
    "        #p = np.sign(epsilon)\n",
    "        if s_plus+(t_minus-s_minus) < s_minus+(t_plus-s_plus):\n",
    "            p = -1\n",
    "        else:\n",
    "            p = 1\n",
    "        ps += [p]\n",
    "    \n",
    "    return np.asarray(ps), np.asarray(thetas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd=1\n",
    "ee=2\n",
    "min(dd,ee)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Practice case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfile = 10\n",
    "npatch=24\n",
    "imgs = np.ones((nfile,npatch,npatch))\n",
    "for l in range(nfile):\n",
    "    for i in range(npatch):\n",
    "        for j in range(npatch):\n",
    "            imgs[l,i,j] = np.random.randint(0,255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_imgs = compute_integral_image(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = np.ones((nfile))*(1/nfile) # weight\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1., -1., -1., -1., -1., -1., -1., -1.,  1., -1.])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### make sudo label\n",
    "y_true = np.ones((nfile))\n",
    "for i in range(len(y_true)):\n",
    "    if i < 9:\n",
    "        y_true[i] = -1\n",
    "    else:\n",
    "        y_true[i] = 1\n",
    "np.random.shuffle(y_true)\n",
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "968"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### feature\n",
    "flist = feature_list(nx=24,ny=24)\n",
    "len(flist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1,  1,  1,  1,  1,  1,  1, -1, -1, -1]),\n",
       " array([ 234.5,  135. ,  -57. , -139.5, -127. ,  -35.5,   97. ,  110.5,\n",
       "        -130.5, -202. ]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p, theta = opt_p_theta(int_imgs, flist, w, 8, y_true)\n",
    "p, theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., 0., 1.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=np.ones((5))\n",
    "a[3] = 0\n",
    "a[0] = 0\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.asarray([i for i in range(5)])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2., 0., 4.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(0,255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_learner(int_img_rep, feat_lst, feat_idx, p, theta):\n",
    "    \"\"\"    \n",
    "    int_img_rep: the N x 64 x 64 numpy matrix of the integral image representation\n",
    "    feat_lst: list of features\n",
    "    feat_idx: integer, index of the feature for this weak learner\n",
    "    p: +1 or -1, polarity\n",
    "    theta: float, threshold\n",
    "    Returns: N x 1 vector of label predictions for the given weak learner\n",
    "    \"\"\"\n",
    "    ones = np.ones((int_img_rep.shape[0]))\n",
    "    feature_vec = compute_feature(int_img_rep=int_img_rep, feat_lst=feat_lst, feat_idx=feat_idx)\n",
    "    return np.sign(p*(feature_vec - theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1., -1.,  1.,  1.,  1.,  1., -1.,  1., -1., -1.])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_learner(int_imgs, flist, 4, p, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1., -1., -1., -1., -1., -1., -1., -1.,  1., -1.])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_rate(int_img_rep, feat_lst, weights, feat_idx, p, theta, y_true):\n",
    "    \"\"\"\n",
    "    int_img_rep: the N x 64 x 64 numpy matrix of the integral image representation\n",
    "    feat_lst: list of features\n",
    "    weights: an N x 1 matrix containing the weights for each datapoint\n",
    "    feat_idx: integer, index of the feature for this weak learner\n",
    "    p: +1 or -1, polarity\n",
    "    theta: float, threshold\n",
    "    y_true: N x 1 matrix of true labels\n",
    "    Returns: the weighted error rate of this weak learner    \n",
    "    \"\"\"\n",
    "    ### Weighted error of h_t\n",
    "    \"\"\"Classifierâ€™s error rate.\n",
    "        This is just the number of misclassifications over the training set \n",
    "        divided by the training set size.\n",
    "    \"\"\"\n",
    "    ## correctness: number of correctly classified data\n",
    "    eval_vec = eval_learner(int_img_rep, feat_lst, feat_idx, p, theta)\n",
    "    error_vec = np.asarray(list(map(lambda x: 1 if x != 0 else 0, (y_true-eval_vec))))\n",
    "    weighted_error = weights*error_vec\n",
    "    weighted_error_rate = np.sum(weighted_error)/int_img_rep.shape[0]\n",
    "    return weighted_error_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 1, 0]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.asarray([1,2,3,4])\n",
    "b = np.asarray([1,0,3,0]) \n",
    "#for idx, _a in enumerate(a):\n",
    "d = list(map(lambda x: 1 if x == 0 else 0, (a-b)))  \n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "erate = error_rate(int_imgs, flist, w, 4, p, theta, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "erate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 5.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt_weaklearner(int_img_rep, weights, feat_lst, y_true):\n",
    "    \"\"\"\n",
    "    int_img_rep: the N x 64 x 64 numpy matrix of the integral image representation\n",
    "    weights: N x 1 matrix of weights of each datapoint\n",
    "    feat_lst: list of features\n",
    "    Returns: the i (feature_idx), p, and theta values for the optimal weak learner\n",
    "    \"\"\"\n",
    "    best_erate, best_feat_idx, best_p, best_theta =1.0e10, 0, 0, 0 # initialization\n",
    "    for feat_idx in range(len(feat_lst)):\n",
    "        p, theta = opt_p_theta(int_img_rep, feat_lst, weights, feat_idx, y_true)\n",
    "        erate = error_rate(int_img_rep, feat_lst, weights, feat_idx, p, theta, y_true)\n",
    "        if best_erate > erate:\n",
    "            # update best error rate\n",
    "            best_erate = erate \n",
    "            best_feat_idx = feat_idx\n",
    "            best_p = p\n",
    "            best_theta = theta\n",
    "    return best_feat_idx, best_p, best_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(227,\n",
       " array([ 1,  1,  1,  1,  1, -1, -1, -1, -1, -1]),\n",
       " array([  83. ,  259.5,  193. ,  108.5,  148. ,  119.5,   24. ,  -83. ,\n",
       "        -100.5,  -60. ]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_weaklearner(int_imgs, w, flist, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(227,\n",
       " array([ 1,  1,  1,  1,  1, -1, -1, -1, -1, -1]),\n",
       " array([  83. ,  259.5,  193. ,  108.5,  148. ,  119.5,   24. ,  -83. ,\n",
       "        -100.5,  -60. ]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_feat_idx, best_p, best_theta = opt_weaklearner(int_imgs, w, flist, y_true)\n",
    "best_feat_idx, best_p, best_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "erate = error_rate(int_imgs, flist, w, best_feat_idx, best_p, best_theta, y_true)\n",
    "erate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1., -1.,  1., -1., -1., -1., -1., -1.,  1.,  0.])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = eval_learner(int_imgs, flist, best_feat_idx, best_p, best_theta)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(weights, _error_rate, y_pred, y_true):\n",
    "    \"\"\"\n",
    "    weights: N x 1 matrix containing the weights of each datapoint\n",
    "    error_rate: the weighted error rate\n",
    "    y_pred: N x 1 matrix of predicted labels\n",
    "    y_true: N x 1 matrix of true labels\n",
    "    Returns: N x 1 matrix of the updated weights\n",
    "    \"\"\"\n",
    "    # scaler params\n",
    "    alpha = 0.5*math.log((1-_error_rate)/_error_rate)\n",
    "    zt = 2*math.sqrt(_error_rate*(1-_error_rate))\n",
    "    new_weights = np.zeros((weights.shape))\n",
    "    for i in range(len(y_true)):\n",
    "        new_weights[i] = weights[i]*math.exp(-1*alpha*y_true[i]*y_pred[i])/zt\n",
    "    return new_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05102041, 0.05102041, 2.5       , 0.05102041, 0.05102041,\n",
       "       0.05102041, 0.05102041, 0.05102041, 0.05102041, 0.35714286])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_w = update_weights(w, erate, y_pred, y_true)\n",
    "new_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
