{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nengo + Nengo_dl + Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kurihana/miniconda3/envs/py3/lib/python3.6/site-packages/nengo_dl/version.py:32: UserWarning: This version of `nengo_dl` has not been tested with your `nengo` version (3.0.0.dev0). The latest fully supported version is 2.8.0.\n",
      "  ((nengo.version.version,) + latest_nengo_version))\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import gzip\n",
    "import os\n",
    "import pickle\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "import nengo\n",
    "import nengo_dl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example in Nengo-DL website\n",
    "[NengoDL with Tnesorflow](https://www.nengo.ai/nengo-dl/v2.1.1/examples/from-tensorflow.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nengo DL How to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kurihana/miniconda3/envs/py3/lib/python3.6/site-packages/nengo_dl/utils.py:158: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n",
      "Build finished in 0:00:00                                                      \n",
      "Optimization finished in 0:00:00                                               \n",
      "|#                        Constructing graph                          | 0:00:00WARNING:tensorflow:From /home/kurihana/miniconda3/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kurihana/miniconda3/envs/py3/lib/python3.6/site-packages/nengo_dl/simulator.py:131: UserWarning: No GPU support detected. It is recommended that you install tensorflow-gpu (`pip install tensorflow-gpu`).\n",
      "  \"No GPU support detected. It is recommended that you \"\n",
      "WARNING:tensorflow:From /home/kurihana/miniconda3/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Construction finished in 0:00:00                                               \n",
      "TensorNode input:\n",
      "t: 0.001\n",
      "x: [[ 0.5 -0.1]]\n",
      "t: 0.002\n",
      "x: [[ 0.5 -0.1]]\n",
      "t: 0.003\n",
      "x: [[ 0.5 -0.1]]\n",
      "t: 0.004\n",
      "x: [[ 0.5 -0.1]]\n",
      "t: 0.0050000004\n",
      "x: [[ 0.5 -0.1]]\n",
      "t: 0.006\n",
      "x: [[ 0.5 -0.1]]\n",
      "t: 0.007\n",
      "x: [[ 0.5 -0.1]]\n",
      "t: 0.008\n",
      "x: [[ 0.5 -0.1]]\n",
      "t: 0.009000001\n",
      "x: [[ 0.5 -0.1]]\n",
      "t: 0.010000001\n",
      "x: [[ 0.5 -0.1]]\n",
      "TensorNode output:\n",
      "[[ 0.501 -0.099]\n",
      " [ 0.502 -0.098]\n",
      " [ 0.503 -0.097]\n",
      " [ 0.504 -0.096]\n",
      " [ 0.505 -0.095]\n",
      " [ 0.506 -0.094]\n",
      " [ 0.507 -0.093]\n",
      " [ 0.508 -0.092]\n",
      " [ 0.509 -0.091]\n",
      " [ 0.51  -0.09 ]]\n"
     ]
    }
   ],
   "source": [
    "with nengo.Network() as net:\n",
    "    # node to provide an input value for the TensorNode\n",
    "    a = nengo.Node([0.5, -0.1])\n",
    "\n",
    "    # a TensorNode function to illustrate i/o\n",
    "    def tensor_func(t, x):\n",
    "        # print out the value of inputs t and x\n",
    "        t = nengo_dl.utils.print_op(t, \"t:\")\n",
    "        with tf.control_dependencies([t]):\n",
    "            x = nengo_dl.utils.print_op(x, \"x:\")\n",
    "\n",
    "        # output t + x\n",
    "        return tf.add(t, x)\n",
    "\n",
    "    # create the TensorNode\n",
    "    b = nengo_dl.TensorNode(tensor_func, size_in=2)\n",
    "    nengo.Connection(a, b, synapse=None)\n",
    "\n",
    "    p = nengo.Probe(b)\n",
    "\n",
    "with nengo_dl.Simulator(net) as sim:\n",
    "    print(\"TensorNode input:\")\n",
    "    sim.run_steps(10, progress_bar=False)\n",
    "    print(\"TensorNode output:\")\n",
    "    print(sim.data[p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in pre_build, scope: SimTensorNodeBuilder\n",
      "in build, scope: while/iteration_0/SimTensorNodeBuilder\n",
      "in post_build, scope: SimTensorNodeBuilder_1\n"
     ]
    }
   ],
   "source": [
    "with nengo.Network() as net:\n",
    "    class TensorFunc:\n",
    "        def pre_build(self, shape_in, shape_out):\n",
    "            # shape_in and shape_out are the input and output shape of\n",
    "            # the TensorNode\n",
    "\n",
    "            print(\"in pre_build, scope:\",\n",
    "                  tf.get_default_graph().get_name_scope())\n",
    "\n",
    "        def __call__(self, t, x):\n",
    "            # this is the main tensornode function, equivalent to the\n",
    "            # tensor_func discussed above\n",
    "\n",
    "            print(\"in build, scope:\",\n",
    "                  tf.get_default_graph().get_name_scope())\n",
    "            return x\n",
    "\n",
    "        def post_build(self, sess, rng):\n",
    "            # post_build is called after the Simulator's underlying\n",
    "            # tf.Session is initialized, and that Session is passed\n",
    "            # in as `sess`. `rng` is the Simulator's random number\n",
    "            # generator.\n",
    "\n",
    "            print(\"in post_build, scope:\",\n",
    "                  tf.get_default_graph().get_name_scope())\n",
    "\n",
    "    a = nengo_dl.TensorNode(TensorFunc(), size_in=1, size_out=1)\n",
    "\n",
    "# build the network\n",
    "with nengo_dl.Simulator(net, progress_bar=False) as sim:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST Nengo DL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download MNIST dataset\n",
    "urlretrieve(\"http://deeplearning.net/data/mnist/mnist.pkl.gz\",\n",
    "            \"mnist.pkl.gz\")\n",
    "with gzip.open(\"mnist.pkl.gz\") as f:\n",
    "    (train_data, _), _, (test_data, _) = pickle.load(\n",
    "        f, encoding=\"latin1\")\n",
    "np.random.shuffle(train_data)\n",
    "\n",
    "n_epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-9b252fb177a3>:12: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-9b252fb177a3>:12: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n"
     ]
    }
   ],
   "source": [
    "n_in = 784\n",
    "n_hidden = 64\n",
    "minibatch_size = 50\n",
    "\n",
    "with tf.Graph().as_default() as auto_graph:\n",
    "    # input\n",
    "    tf_a = tf.placeholder(tf.float32, shape=(minibatch_size, n_in))\n",
    "\n",
    "    # first layer\n",
    "    tf_b = tf.layers.dense(\n",
    "        tf_a, n_hidden, activation=tf.nn.relu,\n",
    "        kernel_initializer=tf.initializers.glorot_uniform())\n",
    "\n",
    "    # second layer\n",
    "    tf_c = tf.layers.dense(\n",
    "        tf_b, n_in, activation=tf.nn.relu,\n",
    "        kernel_initializer=tf.initializers.glorot_uniform())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with nengo.Network() as auto_net:\n",
    "    # input\n",
    "    nengo_a = nengo.Node(np.zeros(n_in))\n",
    "\n",
    "    # first layer\n",
    "    nengo_b = nengo.Ensemble(\n",
    "        n_hidden, 1, neuron_type=nengo.RectifiedLinear())\n",
    "    nengo.Connection(\n",
    "        nengo_a, nengo_b.neurons, transform=nengo_dl.dists.Glorot())\n",
    "\n",
    "    # second layer\n",
    "    nengo_c = nengo.Ensemble(\n",
    "        n_in, 1, neuron_type=nengo.RectifiedLinear())\n",
    "    nengo.Connection(\n",
    "        nengo_b.neurons, nengo_c.neurons,\n",
    "        transform=nengo_dl.dists.Glorot())\n",
    "\n",
    "    # probes are used to collect data from the network\n",
    "    p_c = nengo.Probe(nengo_c.neurons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look into parameter shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_in, n_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(nengo.ensemble.Ensemble, nengo.ensemble.Neurons, nengo.probe.Probe)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(nengo_c), type(nengo_c.neurons),type(p_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set initial neuron gains to 1 and biases to 0\n",
    "for ens in auto_net.all_ensembles:\n",
    "    ens.gain = nengo.dists.Choice([1])\n",
    "    ens.bias = nengo.dists.Choice([0])\n",
    "\n",
    "# disable synaptic filtering on all connections\n",
    "for conn in auto_net.all_connections:\n",
    "    conn.synapse = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build finished in 0:00:00                                                      \n",
      "Optimization finished in 0:00:00                                               \n",
      "Construction finished in 0:00:00                                               ##################################################################################################################################################################################################################################################################################################################| ETA: 0:00:00\n",
      "|                   Training (0%)                  | ETA:  --:--:-- (loss: ---)WARNING:tensorflow:From /home/kurihana/miniconda3/envs/py3/lib/python3.6/site-packages/tensorflow/python/ops/array_grad.py:425: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kurihana/miniconda3/envs/py3/lib/python3.6/site-packages/tensorflow/python/ops/array_grad.py:425: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|#################Training (99%)################# | ETA: 0:00:00 (loss: 0.0110)WARNING:tensorflow:From /home/kurihana/miniconda3/envs/py3/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kurihana/miniconda3/envs/py3/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished in 0:00:21 (loss: 0.0138)                                    \n",
      "Calculation finished in 0:00:01                                                \n",
      "error: 0.0129718995\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define loss function (we could use the pre-defined\n",
    "# `nengo_dl.obj.mse`, but we define it explicitly here\n",
    "# for clarity)\n",
    "def loss(outputs, targets):\n",
    "    return tf.reduce_mean(tf.square(outputs - targets))\n",
    "\n",
    "with nengo_dl.Simulator(auto_net, minibatch_size=minibatch_size) as sim:\n",
    "    # sim.train automatically adds the necessary elements to the\n",
    "    # graph and runs the training loop\n",
    "    # note: the probe acts as the placeholder to feed in target values\n",
    "    sim.train({nengo_a: train_data, p_c: train_data},\n",
    "              tf.train.RMSPropOptimizer(1e-3),\n",
    "              objective={p_c: loss}, n_epochs=n_epochs)\n",
    "\n",
    "    # evaluate performance on test set\n",
    "    error = sim.loss({nengo_a: test_data, p_c: test_data},\n",
    "                     objective={p_c: loss})\n",
    "    print(\"error:\", error)\n",
    "\n",
    "    # display example output\n",
    "    sim.step(data={nengo_a: test_data[:minibatch_size]})\n",
    "    plt.figure()\n",
    "    plt.imshow(sim.data[p_c][0].reshape((28, 28)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
